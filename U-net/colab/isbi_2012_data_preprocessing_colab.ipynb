{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "isbi_2012_data_preprocessing_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing isbi 2012 dataset tiff to png\n",
        "import tifffile as tiff\n",
        "import skimage.io as io\n",
        "import os"
      ],
      "metadata": {
        "id": "aixS59E525c1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZeAV1gj21Mh",
        "outputId": "fbeb4eaf-1b64-40cd-9b7d-3bc1f1ec11e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train img tiff file shape : (30, 512, 512)\n",
            "train label tiff file shape : (30, 512, 512)\n",
            "test img tiff file shape : (30, 512, 512)\n"
          ]
        }
      ],
      "source": [
        "preprocessed_train_img_folder_path = os.path.join('isbi_2012', 'preprocessed', 'train_imgs')\n",
        "preprocessed_train_label_folder_path = os.path.join('isbi_2012', 'preprocessed', 'train_labels')\n",
        "preprocessed_test_img_folder_path = os.path.join('isbi_2012', 'preprocessed', 'test_imgs')\n",
        "\n",
        "train_images = tiff.imread(os.path.join('isbi_2012', 'raw_data', 'train-volume.tif'))\n",
        "train_labels = tiff.imread(os.path.join('isbi_2012', 'raw_data', 'train-labels.tif'))\n",
        "test_images = tiff.imread(os.path.join('isbi_2012', 'raw_data', 'test-volume.tif'))\n",
        "\n",
        "print('train img tiff file shape :', train_images.shape)\n",
        "print('train label tiff file shape :',train_labels.shape)\n",
        "print('test img tiff file shape :', test_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if preprocessing folder path exists\n",
        "if not os.path.exists(preprocessed_train_img_folder_path):\n",
        "  os.mkdir(preprocessed_train_img_folder_path)\n",
        "  os.mkdir(preprocessed_train_label_folder_path)\n",
        "  os.mkdir(preprocessed_test_img_folder_path)\n",
        "\n",
        "for image_index, zip_element in enumerate(zip(train_images, train_labels, test_images)):\n",
        "  each_train_image, each_train_label, each_test_image = zip_element\n",
        "\n",
        "  io.imsave(os.path.join(preprocessed_train_img_folder_path, f\"{image_index}.png\"), each_train_image)\n",
        "  io.imsave(os.path.join(preprocessed_train_label_folder_path, f\"{image_index}.png\"), each_train_label)\n",
        "  io.imsave(os.path.join(preprocessed_test_img_folder_path, f\"{image_index}.png\"), each_test_image)\n",
        "\n",
        "print('ISBI 2012 Preprocessing finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBLFxGTq3org",
        "outputId": "106f70e7-6d75-4cbf-9807-f2b8d96f4a9f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ISBI 2012 Preprocessing finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train_isbi_2012.py"
      ],
      "metadata": {
        "id": "ripGii8d4mgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from absl import flags\n",
        "from absl import app\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "K6PPaje24pBG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아 왜 install이 안 되는거지..."
      ],
      "metadata": {
        "id": "FYKA67sO6b72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install UNET_ISBI_2012"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TRRldmm5f1G",
        "outputId": "8733163d-a789-454b-f1e4-1c3c16521bb0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement UNET_ISBI_2012 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for UNET_ISBI_2012\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model import UNET_ISBI_2012\n",
        "from loss import binary_loss_object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "4ptfLdPQ5cZw",
        "outputId": "e58c765f-f837-4581-dd4f-2bd650a8f2a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-de19784aa5ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUNET_ISBI_2012\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinary_loss_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "flags.DEFINE_string('checkpoint_path', default='saved_model_isbi_2012/unet_model.h5', help='path to a directory to save model checkpoints during training')\n",
        "flags.DEFINE_string('tensorboard_log_path', default='tensorboard_log_isbi_2012', help='path to a directory to save tensorboard log')\n",
        "flags.DEFINE_integer('num_epochs', default=5, help='training epochs')\n",
        "flags.DEFINE_integer('steps_per_epoch', default=2000, help='steps per epoch')\n",
        "flags.DEFINE_integer('num_classes', default=1, help='number of prediction classes')\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "# set configuration value\n",
        "batch_size = 2\n",
        "learning_rate = 0.0001\n"
      ],
      "metadata": {
        "id": "68-wiizf4xaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize isbi-2012 data\n",
        "def normalize_isbi_2012(input_images, mask_labels):\n",
        "  # 0~255 -> 0.0~1.0\n",
        "  input_images = input_images / 255\n",
        "  mask_labels = mask_labels / 255\n",
        "\n",
        "  # set label to binary\n",
        "  mask_labels[mask_labels > 0.5] = 1\n",
        "  mask_labels[mask_labels <= 0.5] = 0\n",
        "\n",
        "  return input_images, mask_labels"
      ],
      "metadata": {
        "id": "oOeK4rsq4xX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make data generator\n",
        "def make_train_generator(batch_size, aug_dict):\n",
        "  image_gen = ImageDataGenerator(**aug_dict)\n",
        "  mask_gen = ImageDataGenerator(**aug_dict)\n",
        "\n",
        "  # set image and mask same augmentation using same seed \n",
        "  image_generator = image_gen.flow_from_directory(\n",
        "      directory='./isbi_2012/preprocessed',\n",
        "      classes = ['train_imgs'],\n",
        "      class_mode = None,\n",
        "      target_size = (512, 512),\n",
        "      batch_size = batch_size,\n",
        "      color_mode='grayscale',\n",
        "      seed=1\n",
        "      )\n",
        "  mask_generator = mask_gen.flow_from_directory(\n",
        "      directory='./isbi_2012/preprocessed',\n",
        "      classes = ['train_labels'],\n",
        "      class_mode = None,\n",
        "      target_size = (512, 512),\n",
        "      batch_size = batch_size,\n",
        "      color_mode='grayscale',\n",
        "      seed=1\n",
        "      )\n",
        "  train_generator = zip(image_generator, mask_generator)\n",
        "  for (batch_images, batch_labels) in train_generator:\n",
        "    batch_images, batch_labels = normalize_isbi_2012(batch_images, batch_labels)\n",
        "    \n",
        "    yield (batch_images, batch_labels)"
      ],
      "metadata": {
        "id": "IUXmgPOy4xVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display image\n",
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Xxdqe6jj4xTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display image and save\n",
        "def display_and_save(display_list, epoch):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.savefig(f'epoch {epoch}.jpg')"
      ],
      "metadata": {
        "id": "yk-j-jOK4xRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction mask\n",
        "def create_mask(pred_mask):\n",
        "  pred_mask = np.where(pred_mask > 0.5, 1, 0)\n",
        "\n",
        "  return pred_mask[0]\n",
        "\n",
        "# show prediction\n",
        "def show_predictions(model, sample_image, sample_mask):\n",
        "  display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
        "\n",
        "# display and save prediction\n",
        "def save_predictions(epoch, model, sample_image, sample_mask):\n",
        "  display_and_save([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))], epoch)\n",
        "\n",
        "# set custom callback\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, unet_model, sample_image, sample_mask):\n",
        "    super(CustomCallback, self).__init__()\n",
        "    self.unet_model = unet_model\n",
        "    self.sample_image = sample_image\n",
        "    self.sample_mask = sample_mask\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    save_predictions(epoch+1, self.unet_model, self.sample_image, self.sample_mask)\n",
        "    print (f'\\n에포크 이후 예측 예시 {epoch+1}\\n')\n"
      ],
      "metadata": {
        "id": "NXujthPL4xOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(_):\n",
        "  # set augmentation\n",
        "  aug_dict = dict(rotation_range=0.2,\n",
        "                      width_shift_range=0.05,\n",
        "                      height_shift_range=0.05,\n",
        "                      shear_range=0.05,\n",
        "                      zoom_range=0.05,\n",
        "                      horizontal_flip=True,\n",
        "                      fill_mode='nearest')\n",
        "\n",
        "  # make generator\n",
        "  train_generator = make_train_generator(batch_size, aug_dict)\n",
        "\n",
        "  # data sanity check\n",
        "  for iter, batch_data in enumerate(train_generator):\n",
        "    if iter >= 2:  # manually detect the end of the epoch\n",
        "      break\n",
        "    batch_image, batch_mask = batch_data[0], batch_data[1]\n",
        "    sample_image, sample_mask = batch_image[0], batch_mask[0]"
      ],
      "metadata": {
        "id": "yQFFvfhA4xMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # data display\n",
        "  display([sample_image, sample_mask])\n",
        "\n",
        "  # create ISBI-2012 UNET model\n",
        "  unet_model = UNET_ISBI_2012(FLAGS.num_classes)\n",
        "\n",
        "  # show prediction before training\n",
        "  show_predictions(unet_model, sample_image, sample_mask)\n",
        "\n",
        "  # set optimizer\n",
        "  optimizer = tf.optimizers.Adam(learning_rate) \n",
        "\n",
        "  # check if checkpoint path exists\n",
        "  if not os.path.exists(FLAGS.checkpoint_path.split('/')[0]):\n",
        "    os.mkdir(FLAGS.checkpoint_path.split('/')[0])\n",
        "\n",
        "  # restore latest checkpoint\n",
        "  if os.path.isfile(FLAGS.checkpoint_path):\n",
        "    unet_model.load_weights(FLAGS.checkpoint_path)\n",
        "    print(f'{FLAGS.checkpoint_path} checkpoint is restored!')\n"
      ],
      "metadata": {
        "id": "uPUkk3D-4xKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # set callback\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(FLAGS.checkpoint_path, monitor='loss', verbose=1, save_best_only=True)\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=FLAGS.tensorboard_log_path)\n",
        "  custom_callback = CustomCallback(unet_model, sample_image, sample_mask)\n",
        "\n",
        "  # set compile\n",
        "  unet_model.compile(optimizer = optimizer, loss = binary_loss_object, metrics = ['accuracy'])\n",
        "\n",
        "  # start training\n",
        "  unet_model.fit_generator(train_generator,\n",
        "                           steps_per_epoch=FLAGS.steps_per_epoch,\n",
        "                           epochs=FLAGS.num_epochs,\n",
        "                           callbacks=[model_checkpoint_callback, tensorboard_callback, custom_callback])\n"
      ],
      "metadata": {
        "id": "2X1sVxem4xIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  app.run(main)"
      ],
      "metadata": {
        "id": "C63qDTg_5K3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "19_Jvwdy5K1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O5fYKjea5KzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0U-2fSOC5Kwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "970e7Sfl5Kub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EKtI2gHy5KsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}